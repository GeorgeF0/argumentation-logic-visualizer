\documentclass[11pt,twoside,a4paper]{report}

\usepackage{fullpage}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{forest}
\usepackage{listings}
\usepackage{color}
\usepackage[round]{natbib}

\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=blue,  %choose some color if you want links to stand out
}
\hypersetup{linktocpage} %in order to make only the numbers in the table of contents clickable

\forestset{
forestyle/.style={
	for tree={
		edge={<-,>=latex},
		l sep=1cm,
		circle,
		minimum size=12pt,
		anchor=west,
		where={iseven(level)}
			{edge={green!80},
			draw=green!80,
			fill=green!20
		}
			{edge={red!80},
			draw=red!80,
			fill=red!20
		},
		if={level>1}
		{s sep=1.3cm}
		{s sep=2cm}
	}
},
every node/.style={anchor=west,right,font=\sffamily,xshift=7pt,yshift=1pt}
}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Prolog,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  identifierstyle=\color{blue},
  breaklines=true,
  breakatwhitespace=true
  tabsize=3,
  captionpos=b
}

\author{Giorgos Flourentzos}
\title{Argumentation Logic Visualizer}
\begin{document}
\maketitle
\tableofcontents

\chapter{Introduction}

Formal logic is a standard method of giving validity to arguments. However, formal logic trivializes in the presence of inconsistencies, thus becoming inflexible when reasoning about inconsistent theories. Additionally, the Reductio ad Absurdum rule is used freely; under this rule the derived inconsistency can be reached without necessarily using the hypothesis assumed at the beginning of the rule's application. In argumentation, this translates to reaching a conclusion with an argument that has nothing to do with the topic of the conversation.

Argumentation Logic is a new argumentation framework proposed by Professor Antonis Kakas (University of Cyprus, Cyprus), Professor Paolo Mancarella (Universit\'a di Pisa, Italy) and Dr Francesca Toni (Imperial College London, United Kingdom). It is a framework based on propositional logic that allows reasoning closer to the way humans do. Argumentation Logic does not trivialize in the presence of inconsistencies.

Argumentation Logic is largely based on the already established natural deduction system. The major difference however lies in the fact that it restricts the use of the Reductio ad Absurdum (known as "not introduction") rule in a way that the assumed hypothesis must be critical to the application of that rule. Argumentation Logic can be seen from an argumentative point of view, as a debate between a proponent who puts forth arguments and defends them against an opponent, who in turn tried to attack those arguments. The arguments are sets of propositional sentences. The argument of the proponent is successful and a conclusion is therefore drawn if it can be successfully defended against the attacks made by the opponent. Argumentation Logic is a recent addition to the field of logic and remains partly unexplored.

The idea is to implement a simple and flexible GUI that will allow for the construction of valid propositional Argumentation Logic natural deduction proofs. In addition, the implemented software will be able to visualize the proofs as exchanges of arguments between proponent and opponent. This is an attempt to enable further research and study of Argumentation Logic as an established method for reasoning about potentially inconsistent environments in a human-like way, with potential applications in artificial intelligence.
The project is split into seven steps which build on top of each other.

\section{Step 1: Basic Natural Deduction Proof System}
The first step requires a natural deduction proof system that can find the steps required to reach a goal, given the theory and the goal that must be met. The aim of this step is to provide the basis on which to build the Argumentation Logic framework.

\section{Step 2: Improving the Proof System}
The second step requires the natural deduction proof system to be able to produce proofs with natural deduction rules applied with variable and configurable priorities and have the ability to look for proofs of a particular maximum length. This step might not be required depending on the implementation of the proof system in the previous step. Therefore the aim of this stage is to only facilitate the implementation of the proof system and has no bearing on the exploration of Argumentation logic.

\section{Step 3: Genuine Absurdity Property}
The third step involves the processing of produced natural deduction proofs in order to check the presence of the Genuine Absurdity Property. This property is closely tied to the identification of natural deduction proofs that are compatible with (that is, supported by) Argumentation Logic. Compatible proofs can be visualized as arguments between two debaters as in the following step.

\section{Step 4: Argumentation Logic Visualization}
The fourth step requires the construction of a GUI that allows the visualization of Argumentation Logic proofs as sets of arguments. The GUI can feature several extensions such as step-by-step building of an Argumentation Logic proof, saving and loading generated proofs, conversion between natural deduction and argumentation and so on.

\section{Step 5: Converting Natural Deduction Proofs to Argumentation Logic Proofs}
The fifth step revolves around the conversion of natural deduction proofs that are unsupported by Argumentation Logic (proofs that do not follow the Genuine Absurdity Property) to compatible ones. It can be shown in the technical report on Argumentation Logic that any proof not following the Genuine Absurdity Property can be converted to one that does. The aim of this step is to allow the possibility of virtually any natural deduction proof to be visualized from an argumentative view.

\section{Step 6: Re-Introduction of Disjunction and Implication Connectives}
The sixth step involves the introduction of the disjunction and implication connectives. It is shown in the technical report on Argumentation Logic that for consistent theories using only conjunction and negation, Propositional Logic is equivalent to Argumentation Logic. The use of disjunction and implication remain partly subject for future work. The aim of this step is to explore further this area.

\section{Step 7: Paraconsistency}
The seventh and final step ventures into how Argumentation Logic can allow for reasoning within an inconsistent environment. The aim of this step is to probe the notion of para-consistency of Argumentation Logic.

In conclusion, this project explores the premise of Argumentation Logic, a recent framework based on natural deduction of propositional logic that allows proofs to be visualized as an exchange of arguments. To aid the understanding of Argumentation Logic, a software will be created that enables the construction and visualization of proofs that adhere to this logic. At the time of writing, there is no published work in this area, and the nature of this project is investigative.

\chapter{Background}

\section{Argumentation Theory}
\label{sec:argtheory}
Recommended Reading: \citep*{argumentationinai}

\subsection{What is Argumentation Theory}
Exactly what defines an argument varies between different sources in argumentation theory. Douglas Walton defines an argument as being made of three parts: a conclusion, the premises based on which the conclusion is derived and an inference, which links the premises to the conclusion. Arguments are sets of propositions of some format and they tend to attack or defend other arguments in a conversation. They can be used in order to choose a course of action, decide for or against a decision, or find common ground between two (or more) parties. There are several packages that draw arguments as chains of attacks and defenses which will be discussed briefly in \autoref{sec:vizargtools}.

Argumentation differs from the traditional approaches of inference based on deductive logic. The difference lies in that traditional approaches (such as propositional calculus) prove that the conclusion sought after does indeed derive from the given premises. The conclusion and theory are both known in advance, and a single inference is made to link the two. This is called a monological approach. On the contrary, argumentation involves a process that looks more like a dialogue (hence it is a dialogical approach) which tries to look at the pros and cons of an argument. The process involves analyzing the arguments set forth for and against the initial argument, and finding strengths and weaknesses. The final outcome is then based on the strongest argument.

\subsection{Attacking Arguments}
There are different ways to attack an argument. Asking a critical question that raises doubt about a previous argument leads to that argument being refuted unless the other party can respond with a satisfactory answer. Questioning an argument's premises or inference is another way of attack. Putting forward a counter-argument (an argument that reaches the opposite conclusion of the first argument) or arguing that the premises are irrelevant to the conclusion (this problem, introduced by the Reductio ad Absurdum rule concerns Argumentation Logic) are also valid attacks. Different views exist about what constitutes an attack and what not; for example, Krabbe suggests his own seven ways to react to an argument \citep*{reasonreclaimed}.

\subsection{Types of Arguments}
Generally, arguments belong to three different categories, based on how the inference that links the conclusion to the evidence was made: deductive, inductive and defeasible. Defeasible arguments are different from inductive in that they cannot be anticipated statistically. For example, "Adults can drive. I am an adult. Therefore, I can drive." is an example of deductive reasoning, but in a defeasible environment it could be the case that I still cannot drive because of a broken leg. Argumentation Logic, as it is based on natural deduction, involves arguments of the deductive kind.

\subsection{Argumentation Example}
An example of an argument between two parties is given below:

\begin{enumerate}
\item
Student: Higher grades mean higher employability. Decreasing the volume of the curriculum will increase student performance and allow them to get higher marks. Therefore, we should decrease the volume of taught material.
\item
Director of Studies: How do you know that decreasing the volume of the material taught will improve students' marks?
\item
Student: Students will have more time to digest the curriculum and revise for the exams. In that way, they will achieve higher marks in the exams and overall grades.
\item
Director of Studies: Weakening the curriculum will make your degree less desirable at the same time, thus reducing your employability.
\item
Student: How do you know that our degree will become less important?
\item
Director of Studies: Reports we have gathered from the industry indicate that students from this university are of high demand because of their vast knowledge of material not covered in most other universities.
\end{enumerate}

The student sets the premise by stating that higher grades imply higher employability and smaller curriculum implies higher grades. His conclusion is that the taught material should be decreased. The director of studies attacks the student's argument by challenging the second premise. The student tries to defend himself by providing a concrete argument as to how a smaller curriculum can lead to better grades. The director of studies cannot attack that argument, and thus poses a different (yet relevant) argument: reducing the material offered will make the degree less attractive.  The student then attacks this argument by questioning it (the same way the director of studies questioned the student's initial argument). In the end, the director supplies facts that support his argument, leading to a counter-example that suggests that cutting down the curriculum will actually result in lower employability. The debate ends, as the student can no longer support his argument.

\subsection{Relevance}
\label{subsec:relevance}
As briefly mentioned before, irrelevance is one type of fallacy concerning argumentation theory. Under this fallacy, a debater can put forth an argument with premises that are of no relevance to the conversation at hand, perhaps stray away into a different matter and reach a conclusion that otherwise could not be met. Alternatively, this issue could cause the conversation to lead to nowhere. This will be discussed further when explaining how Argumentation Logic restricts the use of the Reductio ad Absurdum rule in order to establish a form of relevance (as seen in \autoref{subsec:gap}).

\subsection{Abstract Argumentation Framework}
\label{subsec:abrstrargframework}
An argumentation framework is a framework that is established in order to allow for formal study of argumentation theory. Perhaps the most basic argumentation framework is the widely known abstract argumentation framework \citep*{dung95}. This is a very simple framework that is defined by a set containing the arguments set forth by a party and the attack relation, a binary relation that defines which argument in the set attacks which.

In formal notation, an abstract argumentation framework is usually given by the tuple
\[\langle Args, Att\rangle\]
where:
\begin{itemize}
\item
Args is the set of all possible arguments that are relevant to the subject modeled by the argumentation framework
\item
Att is the binary relation $Args\times Args$ where a $(a, b)\in Att$ means that argument $a$ attacks argument $b$.
\end{itemize}

For example consider the small abstract argumentation framework that models the possibility of going hiking if it is raining. Assume for this example that going hiking is not possible if it is raining, unless a raincoat is at hand. Additionally, not going hiking on a beautiful sunny day is out of the question, unless of course it happens to be very muddy (from the rain the night before).

Our arguments can be $c$ for having a raincoat, $r$ to indicate that it is raining, $h$ for deciding to go on a hike, $h'$ for deciding against hiking, $s$ for being sunny and finally $m$ for being muddy. Thus $Args = \{c, r, h, h', s, m\}$.

In this framework, argument $r$ attacks argument $h$ (rain does not allow hiking), and argument $c$ attacks argument $r$ (having a raincoat guards against the rain). Also, $s$ attacks $h'$ (as it would be a shame to not go hiking on a sunny day) and $m$ attacks $s$ (since a lot of mud will incur a lot of hand-washing later on). Arguably, $h$ attacks $h'$ and vice-versa, as the two arguments are mutually exclusive. Thus $Att = \{(r, h), (c, r), (s, h'), (m, s), (h, h'), (h', h)\}$.

The abstract argumentation framework resulting from this example will then be of the form $\langle Args, Att\rangle$.

There are very many extensions to Dung's abstract argumentation framework for different reasons, such as aiming to cover limitations of this framework or tailoring it to better fit particular domains. Examples of extensions of this framework are the abstract bipolar argumentation framework \citep*{bipolarAA}, assumption-based argumentation \citep*{aba}, logic-based argumentation frameworks \citep*{logicAA} and value-based argumentation frameworks \citep*{valueAA}.

It will be seen later on in \autoref{subsec:alfdef} that Argumentation Logic establishes its own framework by building directly on top of an abstract argumentation framework.

\subsection{Visualization of Abstract Argumentation Framework}
\label{subsec:aafviz}
An abstract argumentation framework can be seen from a graphical point of view. The arguments $Args$ form nodes in a graph, and the attack relation $Att$ forms the edges. The above example, with $\langle Args, Att\rangle$ (where $Args = \{c, r, h, h', s, m\}$ and $Att = \{(r, h), (c, r), (s, h'), (m, s), (h, h'), (h', h)\}$), can be visualized in \autoref{fig:aafviz}.

\begin{figure}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{h};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}r}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}c}}]
	]
    [,edge={<->}, edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}h'}}
    	[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}s}}
    		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}m}}]
    	]
	]
]
\end{forest}}
\caption{Visualization of abstract argumentation example in \autoref{subsec:abrstrargframework}\label{fig:aafviz}}
\end{figure}

\section{Natural Deduction}
Recommended Reading: \citep*[pp. 17-225]{languageproofandlogic}

\subsection{Rules for Propositional Logic}
\label{subsec:logicrules}
The rules for propositional logic used throughout this paper are as follows:

\begin{tabular}{|c|c|c|c|c|c|}
\hline
$\wedge I:\frac{\phi, \psi}{\phi\wedge\psi}$ &
$\wedge E:\frac{\phi\wedge\psi}{\psi}$ &
$\wedge E:\frac{\phi\wedge\psi}{\phi}$ &
$\vee I:\frac{\psi}{\phi\wedge\psi}$ & 
$\vee I:\frac{\phi}{\phi\wedge\psi}$ &
$\vee E:\frac{\phi\vee\psi, [\phi...\chi], [\psi...\chi]}{\chi}$ \\
\hline
$\rightarrow I:\frac{[\phi...\psi]}{\phi\rightarrow\psi}$ & 
$\rightarrow E:\frac{\phi, \phi\rightarrow\psi}{\psi}$ &
$\neg I:\frac{[\phi...\bot]}{\neg\phi}$ &
$\neg E:\frac{\neg\neg\phi}{\phi}$ &
$\bot I:\frac{\phi, \neg\phi}{\bot}$ &
$\bot E:\frac{\bot}{\phi}$ \\
\hline
\end{tabular}

Note: the notation $[\phi...\psi]$ means a derivation of $\psi$ with hypothesis $\phi$.

\subsection{Example of Natural Deduction Proof}
An example of a natural deduction proof can be shown below. The format of natural deduction proofs will follow the format of this example:

Assume theory $T = \{\alpha\rightarrow\beta\rightarrow\neg\gamma, \neg\gamma\wedge\beta\}$ and prove $\neg\alpha$.

\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\alpha\rightarrow\beta\rightarrow\gamma&\mbox{given}\cr
2&\neg\gamma\wedge\beta&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&3&\alpha&\mbox{hypothesis}&\cr
&4&\beta\rightarrow\neg\gamma&\rightarrow E(1,3)&\cr
&5&\beta&\wedge E(2)&\cr
&6&\gamma&\rightarrow E(1,5)&\cr
&7&\neg\gamma&\wedge E(2)&\cr
&8&\bot&\bot I(6,7)&\cr
%
\noalign{\hrule}}}\,\cr
%
9&\neg\alpha&\neg I(3,8)\cr
}}\]

A box is used to contain the hypotheses, derivations inside which cannot be used outside. Each derivation is numbered on the left, and reasons (i.e. rules used) for each derivation are given on the right, following the rules defined in the previous section. Theory is indicated as "given", and assumptions (hypotheses) are indicated as "hypothesis" at the beginning of a sub-derivation (inner box).

\section{Argumentation Logic}
Recommended Reading: \citep*{alpaper}

\subsection{Introduction}
This section gives a brief introduction of the concepts behind Argumentation Logic, as found in the technical report. Section Exploring Argumentation Logic shows how these concepts are used to build the visualization tool.

Argumentation Logic builds a bridge between argumentation theory and propositional logic. This duality is formed by combining notions from both argumentation theory and natural deduction. For consistent theories, Argumentation Logic is equivalent to propositional logic, but it also extends into a para-consistent logic for inconsistent theories. From the argumentation point of view, Argumentation Logic can be seen as arguments that are sets of propositional formulas that attack and defend against other arguments. From the propositional logic point of view, Argumentation Logic can be seen as a natural deduction system that restricts the use of the Reductio ad Absurdum rule in order to allow for relevant arguments to be used only. The rest of this section is devoted to explaining the concepts behind this new logic.

\subsection{Argumentation Logic Framework}
In order to establish the Argumentation Logic framework, the notions of "direct derivation" and "direct consistency" must first be defined:

\subsubsection{Direct Derivation}
A direct derivation for a sentence from a theory is a natural deduction derivation of that sentence from the given theory that does not contain any application of the Reductio ad Absurdum rule. If such a derivation exists, then we say that this sentence is directly derived (derived modulo RA) from the theory. For a sentence $\phi$ directly derived from theory $T$, we denote $T\vdash_{MRA} \phi$.
For example, assume theory $T = \{\alpha\rightarrow\beta, \beta\rightarrow\delta\}$, and derive $\alpha\rightarrow\delta$:

\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\alpha\rightarrow\beta&\mbox{given}\cr
2&\beta\rightarrow\delta&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&3&\alpha&\mbox{hypothesis}&\cr
&4&\beta&\rightarrow E(1,3)&\cr
&5&\delta&\rightarrow E(2,4)&\cr
%
\noalign{\hrule}}}\,\cr
%
9&\alpha\rightarrow\delta&\neg I(3,5)\cr
}}\]

This is a direct derivation as the Reductio ad Absurdum rule was not used.

As another example, assume theory $T = \{\alpha\rightarrow\bot\}$ and derive $\neg\alpha$:

\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\alpha\rightarrow\bot&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&3&\alpha&\mbox{hypothesis}&\cr
&4&\bot&\rightarrow E(1,2)&\cr
%
\noalign{\hrule}}}\,\cr
%
9&\neg\alpha&\neg I(2,3)\cr
}}\]

This is not a direct derivation as the Reductio ad Absurdum rule had to be used.

\subsubsection{Classical and Direct Consistency/Inconsistency}
The word "classical" is used to denote the original natural deduction entailment. The word "direct" uses the notion above. A theory is classically inconsistent if a contradiction can be derived from it in the "classical" sense. A theory is directly inconsistent if a contradiction can be derived through a direct derivation. A theory is classically or directly consistent if it is not classically or directly inconsistent, respectively.

In notation, a theory $T$ is
\begin{itemize}
\item
classically inconsistent if $T\vdash\bot$
\item
directly inconsistent if $T\vdash_{MRA}\bot$
\item
classically consistent if $T\nvdash\bot$
\item
directly consistent if $T\nvdash_{MRA}\bot$
\end{itemize}

In a sense, direct derivation capabilities form a subset of those of the classical derivation. Hence, if a theory is classically consistent then it is directly consistent too. A directly consistent theory can be classically inconsistent however, since classical derivation has one more rule for proving contradiction (namely, the Reductio ad Absurdum rule) that direct derivation does not have.

As an example, consider theory $T = \{\alpha\rightarrow\beta, \neg\alpha\rightarrow\gamma, \neg\beta\wedge\neg\gamma\}$ and prove contradiction:

\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\alpha\rightarrow\beta&\mbox{given}\cr
2&\neg\alpha\rightarrow\gamma&\mbox{given}\cr
3&\neg\beta\wedge\neg\gamma&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\alpha&\mbox{hypothesis}&\cr
&5&\beta&\rightarrow E(1,4)&\cr
&6&\neg\beta&\wedge E(3)&\cr
&7&\bot&\bot I(5,6)&\cr
%
\noalign{\hrule}}}\,\cr
%
8&\neg\alpha&\neg I(4,7)\cr
9&\gamma&\rightarrow E(2,8)\cr
10&\neg\gamma&\wedge E(3)\cr
11&\bot&\bot I(9,10)\cr
}}\]

This proof requires the use of the Reductio ad Absurdum rule, without which a contradiction cannot be derived. Thus, this theory is classically inconsistent, but directly consistent.

\subsubsection{Argumentation Logic Framework Definition}
\label{subsec:alfdef}
The Argumentation Logic framework relies on Dung's abstract argumentation framework as defined in \autoref{subsec:abrstrargframework}. It involves a set of arguments (where each argument is a set of propositional sentences) and the attack relation between the arguments. Thus for a given theory $T$, the Argumentation Logic framework becomes
\[\langle Args^T, Att^T\rangle\]
where:
\begin{itemize}
\item
$Args^T = \{T\cup\Sigma\}$ where $\Sigma$ is a set of propositional formulas. Hence all arguments include the starting theory $T$ and potentially more propositional formulas $\Sigma$
\item
$Att^T = \{(b,a) | a,b \in Args^T, a = T\cup\Delta, \Delta\neq\{\}, b = T\cup\Gamma, T\cup\Delta\cup\Gamma\vdash_{MRA}\bot\}$, that is, a set of pairs of arguments, the union of which provides ground for the direct derivation of a contradiction. In other words, $Att^T$ contains all pairs of arguments that don't agree with each other!
\end{itemize}

Since the theory is fixed for the argumentation framework, any argument $a = T\cup\Sigma$  will be referred to only by $\Sigma$. The argument $T\cup\{\}$ will thus be referred to as the empty argument. Note that in the attack relation, the attacked argument cannot be empty and apart from this exception, all attacks are reflexive.
As an example, consider $T = \{\alpha\rightarrow\beta, \alpha\rightarrow\gamma\}$. Here, $\{a\}$ attacks (and is attacked by) $\{\neg\beta\}$ or $\{\neg\gamma\}$. For a directly inconsistent theory, all arguments are hostile to each other since a contradiction can be derived from any possible pair of arguments (the empty argument can still not be attacked).

\subsubsection{Defense Against an Attack}
\label{subsec:alfdef2}
Using the Argumentation Logic framework described above, and taking any argument $a = T\cup\Delta$, an argument $d$ can be described as a defense against $a$ if any of the following is true:
\begin{itemize}
\item
$d = T\cup\{\neg\phi\}$ or $d = T\cup\{\phi\}$ for some sentence $\phi\in\Delta$ or $\neg\phi\in\Delta$ respectively
\item
$d = T\cup\{\}$ and $a\vdash_{MRA}\bot$
\end{itemize}

What this means is that argument $d$ can take an opposing view on one of the sentences in argument $a$ (this can be interpreted as questioning one of the premises or the conclusion of an argument in argumentation theory) or if argument $a$ is self-contradicting, then saying nothing (empty argument) still counts as a defense against that argument.

\subsection{Acceptability Semantics}
This section defines what it means for an argument to be acceptable in Argumentation Logic, as discussed in the technical report.

\subsubsection{Acceptability of Arguments}
Given an argumentation framework $\langle Args^T, Att^T\rangle$ as discussed in the previous section fixed for a consistent theory $T$, with $a,b\in Args^T$, then $a$ is acceptable with respect to $b$, denoted by $ACC^T(a,b)$, if and only if either of the following conditions is met:
\begin{itemize}
\item
$a\subseteq b$
\item
for all $c\in Args^T$ such that $(c,a)\in Att^T$ both of the following are true:
\begin{itemize}
\item
$c\nsubseteq a\cup b$
\item
there is an argument $d\in Args^T$ which defends against $c$ and $ACC^T(d,a\cup b)$
\end{itemize}
\end{itemize}

Intuitively, an argument is acceptable with respect to one other one if it is a subset of it (they share the same ideas), or all of its attacking arguments are not based on the same ideas (are not subsets of the two arguments whose acceptability is under examination) and they can be successfully blocked by other acceptable arguments.

\subsubsection{Non-Acceptability of Arguments}
Similarly to the acceptability of arguments, for argumentation framework $\langle Args^T, Att^T\rangle$ fixed for a consistent theory $T$, with $a,b\in Args^T$, then $a$ is not acceptable with respect to $b$, denoted by $NACC^T(a,b)$, if and only if both of the following conditions are met:
\begin{itemize}
\item
$a\nsubseteq b$
\item
there is an argument $c\in Args^T$ such that $(c,a)\in Att^T$ and either of the following is true:
\begin{itemize}
\item
$c\subseteq a\cup b$
\item
for all arguments $d\in Args^T$ which defend against $c$ it is true that $NACC^T(d,a\cup b)$
\end{itemize}
\end{itemize}

Intuitively, an argument is unacceptable with respect to another if they are different and there is an attacking argument that comes from the same ideas as the arguments under examination and it cannot be defended against (by an acceptable argument). Note that non-acceptability is the exact opposite of acceptability, and so it holds that $NACC^T(a,b) = \neg ACC^T(a,b)$.

\subsubsection{Example of Non-Acceptability}
Consider theory $T = \{\alpha\wedge\beta\rightarrow\bot, \neg\beta\wedge\gamma\rightarrow\bot, \neg\gamma\wedge\delta\rightarrow\bot\}$. $NACC^T(\{a\},\{\})$ holds, because:
\begin{itemize}
\item
$\{a\}\nsubseteq\{\}$, $\{\beta\}$ attacks $\{\alpha\}$ and $\{\neg\beta\}$ is the only defense against $\{\beta\}$, and so it suffices to show that $NACC^T(\{\neg\beta\}, \{\alpha\})$
\item
$\{\neg\beta\}\nsubseteq\{\alpha\}$, $\{\gamma\}$ attacks $\{\neg\beta\}$ and $\{\neg\gamma\}$ is the only defense against $\{\gamma\}$, and so it suffices to show that $NACC^T(\{\neg\gamma\}, \{\alpha\, \neg\beta\})$
\item
$\{\neg\gamma\}\nsubseteq\{\alpha, \neg\beta\}$, $\{\delta\}$ attacks $\{\neg\gamma\}$ and there is unfortunately no defense against it, thus $NACC^T(\{\neg\gamma\}, \{\alpha,\neg\beta\})$, $NACC^T(\{\neg\beta\}, \{\alpha\})$ and in turn $NACC^T(\{\alpha\}, \{\})$ all hold
\end{itemize}

\subsection{Reductio ad Absurdum, Genuine Absurdity Property and Acceptability Semantics}
This section introduces the Genuine Absurdity Property, and relates it to the use of the Reductio ad Absurdum rule and the acceptability semantics.

\subsubsection{RAND Derivations}
\label{subsec:rand}
Reductio ad Absurdum derivations (RAND for short) are natural deduction derivations that are enclosed by a Reductio ad Absurdum rule application. 

Thus a RAND derivation of a propositional formula $\neg\phi$ is a natural deduction derivation of $\neg\phi$ which starts with a hypothesis $\phi$ and reaches a contradiction, allowing for the Reductio ad Absurdum rule to be applied in order to deduce $\neg\phi$.

A sub-derivation (of a certain derivation) is a RAND sub-derivation (of that derivation) if the sub-derivation itself is a RAND derivation. Hence a tree can be formed with the RAND derivation as the root, its RAND sub-derivations as its immediate children, the RAND sub-sub-derivations as the next node level, and so on.

Consider as an example, theory $T = \{\alpha\rightarrow\bot, \beta\rightarrow\bot, \neg\alpha\wedge\neg\beta\wedge\gamma\rightarrow\bot\}$ and prove $\neg\gamma$.

\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\alpha\rightarrow\bot&\mbox{given}\cr
2&\beta\rightarrow\bot&\mbox{given}\cr
3&\neg\alpha\wedge\neg\beta\wedge\gamma\rightarrow\bot&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\gamma&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\alpha&\mbox{hypothesis}&\cr
&6&\bot&\rightarrow E(1,5)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&7&\neg\alpha&\neg I(5,6)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&8&\beta&\mbox{hypothesis}&\cr
&9&\bot&\rightarrow E(2,8)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&10&\neg\beta&\neg I(8,9)&\cr
&11&\neg\alpha\wedge\neg\beta&\wedge I(7,10)&\cr
&12&\neg\alpha\wedge\neg\beta\wedge\gamma&\wedge I(4,11)&\cr
&13&\bot&\bot I(4,12)&\cr
%
\noalign{\hrule}}}\,\cr
%
14&\neg\gamma&\neg I(4,13)\cr
}}\]

This proof can be visualized as a tree with the root being the outer derivation of $\neg\gamma$ and with children the (sub-)derivations of $\neg\alpha$ and $\neg\beta$, as shown in \autoref{fig:randviz}. The exact algorithm for visualizing a proof will be given in \autoref{chap:viz}.

\begin{figure}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\gamma\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\alpha, \neg\beta\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\alpha$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\}$}}]
		]
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\beta$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\}$}}]
		]
	]
]
\end{forest}}
\caption{Visualization of the proof of example in \autoref{subsec:rand}\label{fig:randviz}}
\end{figure}

For a directly consistent theory, if $NACC^T(\{\phi\},\{\})$ holds for some $\phi$, then there is a RAND derivation of $\neg\phi$ from that theory \citep*[p. 18]{alpaper}.

\subsubsection{Genuine Absurdity Property}
\label{subsec:gap}
For the rest of this section, theories are assumed to be expressed using conjunction and negation only. This gives rise to the following property: all sub-derivations of any derivation of a theory are RAND sub-derivations. The following notation (adapted from the technical report) can be used to represent RAND derivations:

\[[\phi:\phi_1, ..., \phi_k; \neg\psi_1, ..., \neg\psi_l: \bot]\]
where $k, l \geq 0$ and
\begin{itemize}
\item
$\phi$ is the hypothesis of this derivation
\item
$\phi_i$ are the hypothesis of parent derivations that this derivation has access to and can make use of
\item
$\psi_i$ are the hypotheses of the children derivations, the negations of which can be used by this derivation
\end{itemize}

This notation can also nest derivations inside one another. From the last example with theory $T = \{\alpha\rightarrow\bot, \beta\rightarrow\bot, \neg\alpha\wedge\neg\beta\wedge\gamma\rightarrow\bot\}$ and proof of $\neg\gamma$, the RAND derivations that took place can be described as follows, using this notation:
\[[\gamma:-;[\alpha:\gamma;-:\bot],[\beta:\gamma;-:\bot]:\bot]\]

Note that the outer derivation has no inherited ancestral hypotheses, and the inner derivations (which correspond to the leaves in the tree) have no child hypotheses; therefore "-" is used to represent empty sequences in the notation.

As a consequence of a RAND derivation, $T\cup\{\phi\}\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\vdash_{MRA}\bot$. That is to say, the theory along with the hypothesis of that derivation and the assistance of parent and child hypotheses can be used to derive a contradiction (which gives ground for the deduction of $\neg\phi$ using the Reductio ad Absurdum rule). 

The Genuine Absurdity Property then states that a RAND derivation satisfies this property if the hypothesis of the derivation must be used in order to derive a contradiction. In other words, the hypothesis must be relevant and without it a contradiction cannot be established in any way. In formal notation this means that $T\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\nvdash_{MRA}\bot$ (note the absence of $\phi$). In addition, all RAND sub-derivations must also follow this property, making it a recursive property.

In terms of argumentation, the violation of the genuine absurdity property can be thought of an argument with premises irrelevant to the conversation at hand (as was discussed in \autoref{subsec:relevance}). RAND derivations satisfying the genuine absurdity property are not guaranteed to exist, except for classically consistent theories \citep*[p. 9]{alpaper}. It can be shown that for a directly consistent theory, if there is a RAND derivation of $\neg\phi$ that fully satisfies the genuine absurdity property then $NACC^T(\{\phi\},\{\})$ holds \citep*[p. 19]{alpaper}.

\subsubsection{Acceptability Semantics With Respect to Propositional Logic}
The technical report presents a series of theorems and proofs that closely relate Argumentation Logic's acceptability semantics to propositional logic \citep*[pp. 10-11]{alpaper}. Below is a summary of properties of the notions of acceptability that demonstrate their connection to notions in propositional logic:
\begin{itemize}
\item
For a classically consistent theory, and a RAND derivation of a negated formula, there exists another RAND derivation of that negated formula that fully satisfies the genuine absurdity property.
\item
For a classically consistent theory $T$, if $T\vdash\phi$ then both $ACC^T(\{\phi\},\{\})$ and $NACC^T(\{\neg\phi\},\{\})$ hold.
\item
For a classically inconsistent theory $T$ such that $NACC^T(\{\neg\phi\},\{\})$ holds, $T\vdash\phi$.
\end{itemize}

The definition of $NACC^T$-entailment is the following: For a classically consistent theory $T$, $\phi$ is $NACC^T$-entailed (written as $T\models_{NACC^T}\phi$) by $T$ if and only if $NACC^T(\{\neg\phi\},\{\})$. Hence the last connection between the acceptability semantics of Argumentation Logic and propositional logic is the following: For a classically consistent theory $T$, $T\models\phi$ if and only if $T\models_{NACC^T}\phi$. 
This result is a direct consequence of the properties mentioned above, and in the case of inconsistent theories a natural generalization can be obtained with the addition of an extra condition defined later.

\subsection{Disjunction and Implication Connectives}
Argumentation Logic establishes an equivalence, for classically consistent theories, between itself and propositional logic, under the notion of $NACC^T$-entailment and standard entailment respectively. This equivalence however works with the conjunction and negation connectives. The relations between conjunction and negation and disjunction and implication are given by $\alpha\vee\beta \equiv \neg(\neg\alpha\wedge\neg\beta)$ and $\alpha\rightarrow\beta \equiv \neg(\alpha\wedge\neg\beta)$. In order to include the disjunction and implication connectives it must be shown that $NACC^T$-entailment can be established both ways for both relations. In other words, for disjunction, it must be shown that $\{\alpha\vee\beta\}\models_{NACC^T}\neg(\neg\alpha\wedge\neg\beta)$ and $\{\neg(\neg\alpha\wedge\neg\beta)\}\models_{NACC^T}\alpha\vee\beta$, and for implication, it must be shown that $\{\alpha\rightarrow\beta\}\models_{NACC^T}\neg(\alpha\wedge\neg\beta)$ and $\{\neg(\alpha\wedge\neg\beta)\}\models_{NACC^T}\alpha\rightarrow\beta$.

Fortunately, for the disjunction, both entailments can be shown \citep*[pp. 11-12]{alpaper}. However, in the case of the implication, only $\{\alpha\rightarrow\beta\}\models_{NACC^T}\neg(\alpha\wedge\neg\beta)$ can be shown. In order for $\{\neg(\alpha\wedge\neg\beta)\}\models_{NACC^T}\alpha\rightarrow\beta$ to be possible, the attacking semantics should be changed to account for this case explicitly \citep*[pp. 12-13]{alpaper}. This topic remains a topic for future work.

\subsection{Paraconsistency}
Argumentation Logic is equivalent to propositional logic for consistent theories, under the notion of $NACC^T$-entailment and standard entailment respectively. In the case of classically inconsistent theories, Argumentation Logic define two new notions, each generalizing from the previous \citep*[pp. 13-15]{alpaper}:

\subsubsection{Directly Consistent Theories}
For a directly consistent theory $T$, $\phi$ is $AL$-entailed by $T$ (written as $T\models_{AL}\phi$ if and only if $ACC^T(\{\phi\},\{\})$ and $NACC^T(\{\neg\phi\},\{\})$. This is a generalization of the $NACC^T$-entailment for classically consistent theories, based on the argumentation perspective of an acceptable argument being successfully defended and not successfully objected against.

$AL$-entailment leads to a form of para-consistency, since it does not trivialize in the case of the application of the Reductio ad Absurdum rule (as is the case with standard entailment) due to the notion of non-acceptability. However, even with this addition, $AL$-entailment is still not applicable to directly inconsistent theories.

\subsubsection{Directly Inconsistent Theories}
The notion of $AL$-entailment above does not work for directly inconsistent theories, as from Argumentation Logic's point of view, the theory is in layman's terms as wrong (inconsistent) as it can get. In terms of Argumentation Logic, if the theory is directly inconsistent (in addition to being classically inconsistent as well), then no matter what argument is put forth, it can always be attacked by the empty argument since $T\vdash_{MRA}\bot$ to begin with. 
For this reason, the entire theory cannot be considered as a whole, and hence a new notion of entailment is established, one that makes use of maximally consistent closure sets. For theory $T$, and $Cn(T) = \{\phi| T\vdash_{MRA}\phi\}$ being the set of all direct consequences of $T$, $\phi$ is $AL+$-entailed by $T$ (written as $T\vdash_{AL+}\phi$) if and only if $T'\vdash_{AL}\phi$ for all maximally directly consistent sets $T'\subseteq Cn(T)$. For directly consistent theories $AL+$-entailment is equivalent to $AL$-entailment. 

\section{Exploring Argumentation Logic}
As briefly described in the introduction to this paper, the project tries to explore Argumentation Logic in seven steps. Much of the work to be done in the latter two stages is exploratory, hence there is no clear description of the potential findings.

\subsection{Step 1: Basic Natural Deduction Proof System}
The first stage requires a natural deduction proof system that can find the steps required to reach a goal, given the theory and the goal that must be met. Natural deduction proofs will be generated using the proof system built in this step, in order to later on (in step 3) check which proofs constitute valid Argumentation Logic proofs, and which can be converted to valid Argumentation Logic proofs (step 5).

\subsection{Step 2: Improving the Proof System}
The second stage requires the natural deduction proof system to be able to produce proofs with natural deduction rules applied with variable and configurable priorities and have the ability to look for proofs of a particular maximum length. This step might not be required depending on the implementation of the proof system in the previous step. Therefore the aim of this stage is to only facilitate the implementation of the proof system and has no bearing on the exploration of Argumentation logic.

\subsection{Step 3: Genuine Absurdity Property}
The third stage involves the processing of produced natural deduction proofs (from stage 1) in order to check the presence of the Genuine Absurdity Property as discussed in the Argumentation Logic section before. This property is closely tied to the identification of natural deduction proofs that are compatible with (that is, supported by) Argumentation Logic. Compatible proofs can be visualized as arguments between two debaters as in the following step, which is the aim of the next stage.

\subsection{Step 4: Argumentation Logic Visualization}
The fourth stage requires the construction of a GUI that allows the visualization of Argumentation Logic proofs as sets of arguments. The proofs can originate from natural deduction proofs created automatically from stage 1 (with the help of stages 3 and 5), or constructed by the user using the GUI. The GUI can feature several extensions such as step-by-step building of an Argumentation Logic proof, saving and loading generated proofs, conversion between natural deduction and argumentation and so on. The visual representation of the arguments is subject to aesthetics, and will be decided during the implementation of this step. However, as an indication of the style of the argumentation map, the arguments will probably be displayed as a Dung graph with nodes containing the arguments (sets of propositional sentences) and attack or defense relations depicted as different styles of arrows connecting the nodes. The graph will have the theory at its root and the arguments will build from it. 

\subsection{Step 5: Converting Natural Deduction Proofs to Argumentation Logic Proofs}
The fifth stage revolves around the conversion of natural deduction proofs that are unsupported by Argumentation Logic (proofs that do not follow the Genuine Absurdity Property) to compatible ones (generated from stages 1 and 3). It can be shown in the technical report on Argumentation Logic that any proof not following the Genuine Absurdity Property can be converted to one that does for a consistent theory. The aim of this step is to allow the possibility of natural deduction proofs to be visualized from an argumentative view.

\subsection{Step 6: Re-Introduction of Disjunction and Implication Connectives}
The sixth stage involves the introduction of the disjunction and implication connectives. It is shown in the technical report on Argumentation Logic that for consistent theories using only conjunction and negation, Propositional Logic is equivalent to Argumentation Logic. The use of disjunction and implication remains partly subject for future work. The aim of this step is to explore further this area.

\subsection{Step 7: Paraconsistency}
The seventh and final stage ventures into how Argumentation Logic can allow for reasoning within an inconsistent environment. The aim of this step is to probe the notion of para-consistency of Argumentation Logic. An implementation of the notions of $AL$-entailment and $AL+$-entailment will be attempted in order to provide visual mapping of arguments coming from (directly or classically) inconsistent theories.

\section{Existing Visual Argumentation Tools}
\label{sec:vizargtools}
There is a plethora of existing argumentation tools, many of which provide visualization of arguments. These tools range in purpose from academic and research or educational to commercial tools used in analyzing legal arguments for analyzing the rationality of arguments presented in a courtroom.

No universal agreement exists on the type of argument maps that should be supported by each tool. Some tools support the Toulmin Model of Argument, which is a model proposed by Stephen Toulmin for analysing arguments in legal matters, later realized to have a wider application than just law \citep*{usesofargument}. Another popular representation format is the Wigmore chart, targeting analysis of legal evidence in trials, which is the work of John Henry Wigmore \citep*[pp. 123-144]{analysisofevidence}. According to Kadane and Schum, a Wigmore chart represents an early version of a Bayesian network \citep*[pp. 66-76]{saccoandvazetti}. However, since many of the available tools target specific applications (sometimes in domains outside of law), they opt to visualize their arguments in ways more fitting to the applications they are intended for.

A conscious effort is being made to consolidate the representation of arguments into a single standard format that will allow the exchange of arguments between different applications. One of the proposed standards is the Argument Interchange Format, which is currently under construction. A short-term problem with this format is that different application-specific requirements, which result in different flavors of the format being implemented, need to be tracked in order to improve compatibility; at the same time, a long-term problem might be the time at which the standard will be cast in stone: if this happens too early, then it will probably not account for all the requirements that might emerge from different argumentation applications, however, if this happens too late, then the ramifications will be too deviant to be brought together into a standard \citep*[p. 401]{argumentationinai}. Another format already in use is the Legal Knowledge Interchange Format (LKIF), an XML schema that extends Web Ontology Language in order to represent legal concepts.

A non-exhaustive list of existing argumentation (visualization) tools is given below:
\begin{itemize}
\item
Araucaria
\item
Argkit \& Dungine
\item
ArguGRID
\item
Arguing Agents Competition (AAC)
\item
ASPARTIX
\item
Carneades
\item
Cohere
\item
Compendium
\item
InterLoc
\item
quaestio-it
\item
Rationale
\end{itemize}

Since AIF remains volatile at the time of this writing, and LKIF is only concerned with legal matters, neither of these formats will be used. The visualization tool produced as part of this project will use its own format to store data, and adoption of AIF might be revisited as a possible extension.

\section{Implementation}
Prolog is the lingua franca when it comes to creating proof systems, due to its in-built ability of backtracking and unification. Thus for the steps 1-3 and 5, a Prolog knowledgebase will be created in order to implement the natural deduction proof system.
JavaScript is a great tool for creating graphs and GUIs, and will therefore be considered when building the GUI tool (step 4). JavaScript works in a browser sandboxed environment, which means that a webserver might be required in order to run the tool. The server could be implemented in any of a variety of languages ranging from JavaScript and Python, to C\# and Java. The server will need to interface with Prolog in order to run the proof system. 
This client-server design will allow for the application to be hosted on a webserver for public use and community feedback, as well, which makes it a great way to introduce Argumentation Logic to the academia and industry alike.

\chapter{Solution Overview}
This chapter aims to introduce the overall structure of the solution and provide justification as to the decisions made that constitute the solution.

\section{Solution Architecture}
\label{sec:solarch}
The entire project has been split into three parts, namely the core, the server and the client. The core contains algorithms and code written in order to implement procedures that allow for the exploration of Argumentation Logic. The server stands between the core and the client, and serves client requests by parsing and converting the requests to Prolog, using the core to run the requests and then replying with the results (after conversion again). The overall architecture is shown in \autoref{fig:archdiag}. The three parts will now be discussed further.

\begin{figure}[h]
\centerline{\includegraphics[scale=0.5]{img/system-diagram.png}}
\caption{The high-level system architecture for the chosen solution\label{fig:archdiag}}
\end{figure}

\subsection{Core}
The first (and arguably most important) part is the actual algorithms and code written to explore Argumentation Logic (henceforth referred to as "core"). The core is written entirely in Prolog, a procedural declarative programming language frequently used in the fields of artificial intelligence, logic and theorem proving. 

Prolog was chosen as the implementation language because it often leads to clean and concise code. Concise code arguably leads to fewer bugs, something very important to this project, as soundness is mandatory. Prolog offers pattern matching, backtracking and unification, making it ideal for creating a theorem proving system.

The Prolog language has many implementations, out of which \href{http://www.swi-prolog.org/}{SWI-Prolog}\footnote{http://www.swi-prolog.org/} was chosen because it is very fast and reliable, open-source and has a large array of helpful libraries and a large community.

\subsection{Server}
The second part of the project is the server. The server is used to load the core, and then serve HTTP (JSON) requests from the client by querying the core and replying with the results.

The server is written in Prolog as well. This has the obvious advantage of interoperability between the core and itself. The core's code (predicates) are loaded as part of the server's code and are used directly, and thus no middleware is required for the communication between the two parts.

The Prolog flavor used for the server is SWI-Prolog, which provides an \href{http://www.swi-prolog.org/pldoc/doc_for?object=section(\%27packages/http.html\%27)}{HTTP package}\footnote{http://www.swi-prolog.org/pldoc/doc\_for?object=section(\%27packages/http.html\%27)} that can set up and run a server with just a few lines of code. This virtually eliminated testing of this part of the project.

The server has exactly two responsibilities:

\begin{itemize}
\item
to serve files needed for the client to run - this includes HTML, JavaScript and CSS files
\item
to respond to requests by converting the JSON requests to Prolog, querying the core, converting the results back to JSON and replying to the client
\end{itemize}

The server is discussed in further detail in \autoref{chap:server}.

\subsection{Client}
The third and final part of the project is the client. The client serves as a front-end to the core, providing a helpful GUI as an alternative to the Prolog (interpreter's) command-line interface. It aims to provide useful facilities such as storage, importing and exporting of proofs and other data, syntax checking and so on.

The client consists of HTML, JavaScript and CSS files that are mainly served by the Prolog server. HTML 5 and JavaScript have become a very powerful combination that allow fast creation of elegant graphical interfaces, with many libraries available for free, making them a natural choice for a GUI.

The client is discussed in further detail in \autoref{chap:client}.

\section{Justification of Solution Architecture}
There are several advantages in splitting the project as mentioned in \autoref{sec:solarch}. However, as with any implementation, there are a few disadvantages as well. The pros and cons are discussed in this section.

\subsection{Advantages of Chosen Architecture}
The focus of the design is modularity and reusability. 

By completely detaching the core as a separate, self-contained module, testing becomes easier and more manageable. The responsibilities of this module become clearer. Since the core is completely detached, it can be run as-is, on the Prolog interpreter command-line just by itself, or it can be attached to a completely different program or GUI implementation or used in a different context.

The server can be swapped with a different implementation if required. This particular implementation is very small, largely due to the nature of the SWI-Prolog HTTP package that allows for a quick set-up of a webserver. The server currently has two responsibilities:

\begin{itemize}
\item
to serve files needed for the client to run - this includes HTML, JavaScript and CSS files
\item
to respond to requests by converting the JSON requests to Prolog, querying the core, converting the results back to JSON and replying to the client
\end{itemize}

An alternate setup can have this server respond only to requests and have a different, finely-tuned server (such as Apache) handle the load-balancing and HTTP requests of the clients. This webserver chaining is similar to how the SWI-Prolog website works at the time of writing - there is an exposed Apache server that redirects requests to a SWI-Prolog server hidden from the outside world. 

Since the project consists of a server and an HTML client, it can readily be hosted online and made available to the public. This way, a wider audience can be reached more quickly, which can result to valuable feedback.

The client is written in HTML, JavaScript and CSS, making it a web application. Advantages of web applications are fast, easy and transparent (to the user) updates, not requiring the user to re-download or update any software and cross-platform compatibility and hence larger availability. Web applications are ideal for incremental improvement, as a consequence of the previous advantages, and since this is largely a research project, in the future, it will be easier for features to be added as they are discovered. Finally, web applications integrate very well with other server-side services such as database access and account management, so the project can easily be extended in the future to support sharing of data and content via user accounts on the server.

\subsection{Disadvantages of Chosen Architecture}
As with every design, there are some drawbacks as well. There is some unavoidable duplication in data structures as different languages are used for the core and the client (Prolog vs JavaScript), and each language has to store and represent the data in some way. Some extra work is needed in order to keep the three parts of the system as modular as possible. Effort has to be made in synchronizing the different parts of the system when external interfaces are changed. For example, if the server is altered to accept a different data structure for the requests, then the client has to be update to provide requests that use the new data structure required by the server. Fortunately, internal changes (for example adding extra predicates or features to the core, adding extra UI elements to the client or revamping the GUI, or optimizing any of the three parts of the system) do not affect each module.

There are some disadvantages that come with web applications as well, but some of them fortunately do not apply to this system. Compatibility and performance issues (compared to native applications) are some of the common problems with web interfaces. Since the server does the heavy lifting the client is left with the responsibility of running the a simple GUI, ruling out any potential issues with performance. Every effort is made to make the Client adhere to standards, reducing the chances of running into compatibility issues with the browser. The main disadvantage however is the need for constant connection to the server. Unless the server is run locally, the client cannot be used as all calculations take place server-side.

\subsection{Structure of Remainder of Report}
The core implementation as well as the findings of this project are discussed in chapters TODO to TODO. An overview of the different features implemented in the core can be found in \autoref{chap:coreoverview}. The server implementation is discussed in more detail in \autoref{chap:server}. The client is discussed in \autoref{chap:client}. The evaluation of this project can be found in \autoref{chap:eval}, and finally, a conclusion is drawn based on the evaluation in \autoref{chap:chiliconclusion}. A full code listing for the core can be found in the Appendix (TODO).

\chapter{Core Functional Overview}
\label{chap:coreoverview}
The core is made of different predicates or procedures that work together in order to provide an ecosystem of functions that can be used to create and manipulate natural deduction proofs and arguments. \autoref{fig:funcmap} provides a functional map that illustrates the different procedures as well as the data flow around them.

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.85]{img/functional-map.png}}
\caption{The high-level functional map for the core\label{fig:funcmap}}
\end{figure}

The main procedures involved are the following:
\begin{itemize}
\item
Theorem Prover (\autoref{chap:prover}): the theorem proof system provides proofs for the given theory and goal
\item
GAP Checker (\autoref{chap:gapcheck}): the Genuine Absurdity Property checker takes a proof and succeeds if the given proof indeed follows the property
\item
Proof Visualizer (\autoref{chap:viz}): the proof visualization predicate takes a proof that follows the Genuine Absurdity Property and returns an argument that can be used to visualize the given proof
\item
Proof Extractor (TODO): this predicate can take an argument (a visualization of a proof) and extract a proof from it
\end{itemize}

In addition to the core module predicates, there are a few client features that can still provide data that can be used by the core modules listed above. These are:
\begin{itemize}
\item
Proof Builder (TODO): provides a method of allowing the user to construct a particular proof
\item
Argument Builder(TODO): provides a method of allowing the user to construct an argument 
\end{itemize}

\chapter{Theorem Proving System}
\label{chap:prover}
TODO

\chapter{Checking for Genuine Absurdity Property}
\label{chap:gapcheck}
Recall from \autoref{subsec:gap} that for a RAND derivation, $T\cup\{\phi\}\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\vdash_{MRA}\bot$, where $k, l \geq 0$ and

\begin{itemize}
\item
$\phi$ is the hypothesis of this derivation
\item
$\phi_i$ are the hypothesis of parent derivations that this derivation has access to and can make use of
\item
$\psi_i$ are the hypotheses of the children derivations, the negations of which can be used by this derivation
\end{itemize}

Moreover, recall that the Genuine Absurdity Property forms a kind of relevance by requiring that the hypothesis $\phi$ is necessary for the derivation of the contradiction. In other words, without $\phi$, a contradiction cannot be established. In formal notation, this would be described as

\[T\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\nvdash_{MRA}\bot\]

Recall, further, that the Genuine Absurdity Property is a recursive property in that any sub-derivations of an application of the Reductio ad Absurdum rule must also follow this property, and finally, that this property is defined only over proofs using conjunction and negation only.

\section{Short Description of Algorithm}
In a nutshell, the algorithm for checking for the Genuine Absurdity Property traverses the proof and keeps track of ancestor hypotheses and child hypotheses as well as the theory given initially. At the beginning the algorithm checks that the given proof is a RAND proof and that it only contains conjunctions and negations of atoms.

At the end of each application of the Reductio ad Absurdum rule the Genuine Absurdity Property is checked by asking the theorem prover in \autoref{chap:prover} to try and prove a contradiction using the given theory, and the ancestor and (negations of the) child hypotheses. That is, we ask the prover to prove that $T\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\vdash_{MRA}\bot$. If that succeeds, then we know that a contradiction could have been reached without the use of the hypothesis in the current application of the Reductio ad Absurdum rule, thus making the proof not follow the property under check.

Before reaching the end of the current application of the $\neg I$ rule, each sub-derivation is also checked that it follows the Genuine Absurdity Property by calling the algorithm again recursively, while adding the current hypothesis to the tracked formulas.

\section{Details of Implementation}
The overall algorithm is split into three stages. The first stage involves checking whether the given proof is a RAND proof. That is, apart from the theory, the proof should only contain an application of the Reductio ad Absurdum rule on the top level. The second stage involves checking whether the given proof has formulas consisting of only conjunction and negation. The third and final stage is the actual check which verifies the Genuine Absurdity Theory.

\begin{lstlisting}[caption={Genuine Absurdity Property top level predicate},label=lst:gaptoppred]
% Checks that the given proof follows the GAP property
% Gap checker assumes valid propositional logic proofs
checkGAP(Proof) :- 
	reverse(Proof, RevProof), 
	checkRAND(RevProof), !,
	checkRestrictedRules(RevProof), !,
	getTheoryAndRevBox(RevProof, Theory, RevBox), !,
	checkRestrictedTheory(Theory), !,
	checkGAP(Theory, _, [], [], RevBox), !.
\end{lstlisting}

\autoref{lst:gaptoppred} shows the top-level predicate where the three stages (checks) can be seen at line 5 for RAND proof, lines 6 and 7 for the restricted use of propositional logic, and finally line 9 for the actual check for the definition of the Genuine Absurdity Property. The format of the proof is the same as that output by the theorem proving algorithm in \autoref{chap:prover}. The three stages are further discussed below.

\subsection{Checking for RAND Proof}
The format of a RAND proof is the following: first, there may or may not be a few steps containing the theory. These are steps that are justified with "given". Following should be a box, and finally, there should be either the goal (derived using the box), or the double negation of the goal (derived using the box) and the goal (derived by $\neg E$).

\begin{lstlisting}[caption={Checking whether a proof is a RAND proof},label=lst:gaprandcheck]
% Checks to see if this proof is a RAND proof to start with
% A RAND proof is of the form: [givens]*, [box], ([step:notE, step:notI]||[step:notI])
checkRAND(Proof) :- checkRAND(givens, Proof).
checkRAND(givens, [box(_)|Proof]) :- checkRAND(box, Proof).
checkRAND(givens, [step(_, [given], _)|Proof]) :- checkRAND(givens, Proof).
checkRAND(box, [step(_, [notI|_], _)]).
checkRAND(box, [step(_, [notI|_], _), step(_, [notE, _], _)]).
\end{lstlisting}

On line 3 of \autoref{lst:gaprandcheck} the \lstinline$checkRAND/1$ predicate starts the check by calling \lstinline$checkRAND/2$ and specifying that it is at the "givens" stage (ie that it is now going through the theory). Line 5 unwinds the proof by iterating through the theory until a box is found and picked up by line 4, which marks the "box" stage. Finally, lines 6 and 7 check that the last step of the proof is the conclusion, which might be preceded by its double negation (which is the product of the $\neg I$ rule and the box before.

\subsection{Checking for Restricted Formulas}
It suffices to check in a proof that the theory is constructed using conjunction and negation, and that the rules applied subsequently belong to the set of $\{\wedge I, \wedge E, \neg I, \neg E, \bot I, \bot E\}$.

\begin{lstlisting}[caption={Checking whether a proof uses only conjunction and negation},label=lst:gaprestrictedcheck]
% Checks to see if the proof consists of ruleset defined over argumentation logic
validRules([andI, andE, notI, notE, falsityI, falsityE, given, check, hypothesis]).
checkRestrictedRules([]).
checkRestrictedRules([step(_, [Reason|_], _)|Proof]) :- 
	validRules(ValidRules), 
	m2(Reason, ValidRules), 
	checkRestrictedRules(Proof).
checkRestrictedRules([box(SubProof)|Proof]) :-
	checkRestrictedRules(SubProof),
	checkRestrictedRules(Proof).
checkRestrictedTheory([]).
checkRestrictedTheory([Given|Theory]) :-
	checkRestrictedFormula(Given),
	checkRestrictedTheory(Theory).
checkRestrictedFormula(X) :- 
	atom(X).
checkRestrictedFormula(and(X, Y)) :-
	checkRestrictedFormula(X),
	checkRestrictedFormula(Y).
checkRestrictedFormula(n(X)) :-
	checkRestrictedFormula(X).
\end{lstlisting}

The predicate \lstinline$checkRestrictedTheory/1$ as shown in \autoref{lst:gaprestrictedcheck} looks at the theory contained in the proof and makes sure that it consists only of atoms, conjunctions and negations. The predicate \lstinline$checkRestrictedRules/1$ shown in \autoref{lst:gaprestrictedcheck} again ensures that rules that could potentially introduce a new construct (such as implication or disjunction) are not used. This predicate probes nested boxes as well so that the entire proof is covered. The predicate \lstinline$m2/2$ on line 6 acts as an alias to the standard \lstinline$member/2$ Prolog predicate.

\subsection{Checking for Genuine Absurdity Property}
The final part of the algorithm deals with the definition of the Genuine Absurdity Property directly.

\begin{lstlisting}[caption={Checking whether a proof follows the Genuine Absurdity Property},label=lst:gapgapcheck]
checkGAP(Theory, _, AncestorHypotheses, ChildHypotheses, []) :-
	a3(Theory, AncestorHypotheses, ChildHypotheses, Context),
	not(proveMRA(Context, [falsity], _)).
checkGAP(Theory, _, AncestorHypotheses, ChildHypotheses, [step(H, [hypothesis], _)|Proof]) :-
	!, checkGAP(Theory, H, AncestorHypotheses, ChildHypotheses, Proof).
checkGAP(Theory, Hypothesis, AncestorHypotheses, ChildHypotheses, [step(_, _, _)|Proof]) :-
	checkGAP(Theory, Hypothesis, AncestorHypotheses, ChildHypotheses, Proof).
checkGAP(Theory, Hypothesis, AncestorHypotheses, ChildHypotheses, [box(BoxProof)|Proof]) :-
	checkGAP(Theory, _, [Hypothesis|AncestorHypotheses], [], BoxProof),
	BoxProof = [step(ChildHypothesis, [hypothesis], _)|_],
	checkGAP(Theory, Hypothesis, AncestorHypotheses, [n(ChildHypothesis)|ChildHypotheses], Proof).
\end{lstlisting}

The format of the proof passed in this predicate is the opposite of that output by the theorem prover in \autoref{chap:prover} in that the steps are in increasing order as one would read the proof on paper. This is due to the work of the \lstinline$getTheoryAndRevBox/3$ predicate called before the check as shown in \autoref{lst:gaptoppred}.

The clause on line 4 of \autoref{lst:gapgapcheck} makes a note of the hypothesis. It is the one and only clause that Prolog chooses upon entering a new box (application of the Reductio ad Absurdum rule). All intermediate steps bear little significance and are hence ignored by this predicate as shown on the clause defined on line 6. 

Child proofs however must be checked for the Genuine Absurdity Property as well as this property is recursive. Line 7 takes that into account. It adds the hypothesis of the current context into the ancestor hypotheses of a new call to the \lstinline$checkGAP/5$ predicate (line 9). If the sub-derivation follows the property, the algorithm continues to add the negation of the sub-derivation hypothesis to the child hypotheses. 

At the end of the current context, when all the child hypotheses have been gathered and checked that they follow the property, the algorithm checks that the property holds for this context as well. This is done by the clause on line 1. The predicate \lstinline$a3/4$ ("append 3 lists") on line 2 merges the theory, ancestor hypotheses and child hypotheses gathered so far into one bundle, and calls for the theorem prover to try and prove a contradiction while purposely excluding the hypothesis of the current context from the bundle (line 3). That is, the theorem prover is given the task of proving $T\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\vdash_{MRA}\bot$. If it succeeds, then the Genuine Absurdity Theory does not hold. If it fails, then so far the property holds.

\section{Example Walkthrough}
This example will focus on the \lstinline$checkGAP/5$ predicate shown in \autoref{lst:gapgapcheck}. Consider a proof with theory $\{\neg(\beta\wedge\alpha), \neg(\neg\beta\wedge\gamma), \neg(\alpha\wedge\neg\beta\wedge\neg\gamma)\}$ and goal $\neg\alpha$. The proof is given below: 

\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\beta\wedge\alpha)&\mbox{given}\cr
2&\neg(\neg\beta\wedge\gamma)&\mbox{given}\cr
3&\neg(\alpha\wedge\neg\beta\wedge\neg\gamma)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\beta&\mbox{hypothesis}&\cr
&6&\beta\wedge\alpha&\wedge I(5,4)&\cr
&7&\bot&\bot I(1,6)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&8&\neg\beta&\neg I(5,7)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&9&\gamma&\mbox{hypothesis}&\cr
&10&\neg\beta\wedge\gamma&\wedge I(8,9)&\cr
&11&\bot&\bot I(2,10)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&12&\neg\gamma&\neg I(9,11)&\cr
&13&\alpha\wedge\neg\beta&\wedge I(4,8)&\cr
&14&\alpha\wedge\neg\beta\wedge\neg\gamma&\wedge I(13,12)&\cr
&15&\bot&\bot I(3,14)&\cr
%
\noalign{\hrule}}}\,\cr
%
16&\neg\alpha&\neg I(4,15)\cr
}}\]

The \lstinline$checkGAP/5$ predicate is called with theory $[\neg(\beta\wedge\alpha), \neg(\neg\beta\wedge\gamma), \neg(\alpha\wedge\neg\beta\wedge\neg\gamma)]$, and empty lists for the ancestor and child hypotheses. It is also given the outer box (lines 4 to 15 of the proof). 

Line 4 of the code in \autoref{lst:gapgapcheck} picks up the hypothesis $\alpha$ on line 4 of the proof while at the same time consuming this line of the proof and calling itself again, passing in the hypothesis just picked up. The current context looks like this:
\begin{itemize}
\item
hypothesis: $\alpha$
\item
ancestor hypotheses: $\emptyset$
\item
child hypotheses: $\emptyset$
\end{itemize}

Right away a box is encountered, and the clause on line 8 of the code is executed, which calls itself again and adding the current hypothesis $\alpha$ to the ancestor hypotheses for the recursive call.

Inside the recursive call, in the new context, line 4 executes again, which picks up the new hypothesis $\beta$ and consumes line 5 of the proof. The current context looks like this:
\begin{itemize}
\item
hypothesis: $\beta$
\item
ancestor hypotheses: $\{\alpha\}$
\item
child hypotheses: $\emptyset$
\end{itemize}

Next, the clause on line 6 executes twice in a row, consuming lines 6 and 7 of the proof, essentially ignoring them. The box is now empty.

Since the box is now empty, the first clause (line 1) is executed, which checks that a contradiction cannot be proven just by using the theory and ancestor hypothesis $\alpha$ without the need for the current hypothesis $\beta$. That is, it checks that $T\cup\{\alpha\}\nvdash_{MRA}\bot$.

Having dealt with the child derivation, the algorithm bubbles back up to the execution of line 10 of the code where it previously left off. The box containing lines 5-7 of the proof has been consumed. The child hypothesis is extracted and the negation of it is added to the child hypotheses before recursively calling itself once more. Note that in this context $\alpha$ is the hypothesis and is not a member of the ancestor hypotheses. The current context looks like this:
\begin{itemize}
\item
hypothesis: $\alpha$
\item
ancestor hypotheses: $\emptyset$
\item
child hypotheses: $\{\neg\beta\}$
\end{itemize}

Line 6 of the code steps over line 8 of the proof.

Here, another box is encountered and the clause on line 8 executes once more, adding the current hypothesis $\alpha$ to the ancestor hypotheses for the recursive call.

Inside the recursive call, in the new context, line 4 executes again, which picks up the new child hypothesis $\gamma$ and consumes line 9 of the proof. The current context looks like this:
\begin{itemize}
\item
hypothesis: $\gamma$
\item
ancestor hypotheses: $\{\alpha\}$
\item
child hypotheses: $\emptyset$
\end{itemize}

Lines 10 and 11 of the proof are ignored by the clause on line 6 of the code listing. They are consumed and the box is now empty.

Since this box is now empty, the first clause (line 1) is executed and checks that a contradiction cannot be proven just by using the theory and ancestor hypothesis $\alpha$ without the need for the current hypothesis $\gamma$. That is, it checks that $T\cup\{\alpha\}\nvdash_{MRA}\bot$.

This child derivation is dealt with as well and the algorithm goes back to the execution of line 10 of the code where it left off. The box containing lines 9-11 of the proof has been consumed, and the negation of the child hypothesis $\neg\gamma$ is added to the list of child hypotheses. The current context looks like this:
\begin{itemize}
\item
hypothesis: $\alpha$
\item
ancestor hypotheses: $\emptyset$
\item
child hypotheses: $\{\neg\beta, \neg\gamma\}$
\end{itemize}

Lines 12-15 of the proof are ignored by the clause on line 6 of the code listing, which results in an empty box.

The empty box calls for the clause on line 1 of the code, which checks that a contradiction cannot be proven just by using the theory and children hypotheses $\neg\beta$ and $\neg\gamma$ without the need for the current hypothesis $\alpha$. That is, it checks that $T\cup\{\neg\beta, \neg\gamma\}\nvdash_{MRA}\bot$. After this check, the algorithm ends as the top-level RAND derivation has been proven to follow the Genuine Absurdity Property.

\section{Remarks}
It is worth noting that for the algorithm to work, the theorem prover must return true whenever $T\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\vdash_{MRA}\bot$ is the case. This means that the theorem prover must be complete, in addition to being sound. If the use of an incomplete theorem prover is employed, then a proof might be deemed to be following the Genuine Absurdity Property because the theorem prover might fail to prove the contradiction of a $\neg I$ rule application (without the hypothesis), rather than because it really might be the case that $T\cup\{\phi_1, ..., \phi_k\}\cup\{\neg\psi_1, ..., \neg\psi_l\}\nvdash_{MRA}\bot$. 

\chapter{Visualization of Genuine Absurdity Property Proofs}
\label{chap:viz}
The Argumentation Logic paper does not provide a formal algorithm for visualizing proofs but rather the idea that proofs having the Genuine Absurdity Property can be seen from an argumentative point of view and any abstract argumentation framework can be visualized as shown previously in \autoref{subsec:aafviz}, where an example was given by \autoref{fig:aafviz}. This chapter documents the attempt to provide an algorithm for the visualization of proofs.

\section{Assumptions Made by Algorithm}
The algorithm provided here assumes that the proofs supplied all follow the Genuine Absurdity Property. This property ensures that arguments made in the (corresponding argumentation framework of the) proof are relevant. It might be possible to visualize proofs that do not have this property.

A consequence of this assumption is that the formulas in the proofs consist of conjunctions and negations only, as the Genuine Absurdity Property is defined only for proofs consisting of those constructs.

\section{Description of Algorithm}
\label{sec:vizalg}
In a nutshell, the algorithm moves around the proof in a backwards, $\neg I$-rule's-contradiction-driven approach. It assumes that the hypothesis in the outer box forms the initial argument. At the end of the box, where the contradiction is established, clues can be found as to what the attacks were. Recall from \autoref{subsec:logicrules} that the $\bot I$ rule points to two formulas in the proof of the form $A$ and $\neg A$. Formula $A$ will be either a conjunction of smaller formulas or just one atom. The negated formulas or (negated) atoms form the attack. Naturally, the defenses are the negations of each of those formulas or atoms which will be hypotheses inside boxes which lead to more contradictions recursively. The algorithm repeats itself recursively, until the attacks gathered from the contradictions only form part of the theory or previous hypotheses (defenses higher up the chain).

The algorithm's function will now be demonstrated with the aid of an example. Consider 
the following proof:

\begin{figure}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\beta\wedge\alpha)&\mbox{given}\cr
2&\neg(\neg\beta\wedge\gamma)&\mbox{given}\cr
3&\neg(\alpha\wedge\neg\beta\wedge\neg\gamma)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\beta&\mbox{hypothesis}&\cr
&6&\beta\wedge\alpha&\wedge I(5,4)&\cr
&7&\bot&\bot I(1,6)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&8&\neg\beta&\neg I(5,7)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&9&\gamma&\mbox{hypothesis}&\cr
&10&\neg\beta\wedge\gamma&\wedge I(8,9)&\cr
&11&\bot&\bot I(2,10)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&12&\neg\gamma&\neg I(9,11)&\cr
&13&\alpha\wedge\neg\beta&\wedge I(4,8)&\cr
&14&\alpha\wedge\neg\beta\wedge\neg\gamma&\wedge I(13,12)&\cr
&15&\bot&\bot I(3,14)&\cr
%
\noalign{\hrule}}}\,\cr
%
16&\neg\alpha&\neg I(4,15)\cr
}}\]
\caption{Example proof for the visualization algorithm\label{fig:vizexproof}}
\end{figure}

The initial argument will be found at the top of the outer-most box - the hypothesis $\alpha$. The attacks can be found from the contradiction at the bottom, from line 15. The reasons from the contradiction are lines 3 and 14, which are of the form $\neg A$ and $A$ respectively, where $A = \alpha\wedge\neg\beta\neg\gamma$. $A$ is a conjunction of (negated) atoms, and so the attack against $\alpha$ will be $\{\neg\beta, \neg\gamma\}$. Note that $\alpha$ in $A$ was ignored because it is the argument being attacked itself. The attacks were derived at lines 8 and 12. This is known because the conjunction $A$ is accompanied by the line numbers of its constituents. The defense against $\neg\beta$ and $\neg\gamma$ can be found in the two respective sub-derivations where their negations are assumed. 

$\beta$ is the defense against $\neg\beta$, and at the bottom of the first inner box the attack(s) against it can be found. The conjunction consists of itself and $\alpha$, which is a previous defense. So, after ignoring the hypothesis itself, $\alpha$ remains as the attack. Because this attack was used previously as a defense, it makes no sense to try and defend against it. Thus this part of the algorithm ends here.

$\gamma$ is the defense against $\neg\gamma$, and at the bottom of the second inner box the attack(s) against it can be found. The conjunction here consists of itself and $\neg\beta$. The defense against it and the attack against that can be found in the first inner box and so this part of the algorithm repeats as before.

At the end, the following abstract argumentation framework is extracted, which is drawn in \autoref{fig:vizex}:
\begin{itemize}
\item
arguments: $\{\{\alpha\}, \{\neg\beta, \neg\gamma\}, \{\beta\}, \{\neg\beta\}, \{\gamma\}\}$
\item
attacks: $\{(\{\neg\beta, \neg\gamma\}, \{\alpha\}), (\{\beta\}, \{\neg\beta, \neg\gamma\}), (\{\gamma\}, \{\neg\beta, \neg\gamma\}), (\{\neg\beta\}, \{\gamma\}), (\{\beta\}, \{\neg\beta\})\}$
\end{itemize}

\begin{figure}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\alpha\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\beta, \neg\gamma\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\beta\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
		]
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\gamma\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\neg\beta\}$}}
				[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\beta\}$}}
					[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
				]
			]
		]
	]
]
\end{forest}}
\caption{Visualization of the proof of example in \autoref{fig:vizexproof}\label{fig:vizex}}
\end{figure}

\section{Observations, Remarks and Future Work}
It may be obvious by now that a certain mapping can be established between the hypotheses and contradictions and defenses and attacks. A hypothesis in the proof always represents a defense from the argumentation point of view, and the individual atoms, negated atoms and negated subformulas whose conjunction (along with the negation of their conjunction) forms the contradiction represent the attack from the argumentation point of view. Some of these atoms, negated atoms and formulas can be traced back to conclusions of $\neg I$ rules, thus it can be said that conclusions of $\neg I$ rules (ie the results of the boxes) form some part of an attack.

When using this algorithm, there is always one attack per argument, but there can be many defenses. Each defense is the negation of an atom of an attack (argument). Both the attacks and defenses follow their respective definitions as described in the original paper and in \autoref{subsec:alfdef} and \autoref{subsec:alfdef2}.

When considering the formulas of the conjunction that constitutes an attack, all formulas that are part of the theory or the argument under attack are ignored. Absence of any remaining formulas signifies an attack by the empty set. This is shown by the example in \autoref{fig:emptysetattack}.

Although the argumentation framework shown in \autoref{fig:vizex} could have been drawn so that argument $\{\beta\}$ on the left side of the ramification attacks $\{\neg\beta\}$ on the right, the algorithm repeats the whole branch in the drawing. This choice has a couple of implications. Firstly the generated diagram is always a tree, as chains of arguments are "expanded" or "ironed out" regardless of whether natural deduction proofs made use of sibling $\neg I$ applications. Take the example given in \autoref{fig:vizexproof}. The second inner box makes use of the conclusion $\neg\beta$ that was derived from the first inner box in order to reduce redundancy. The algorithm turns this proof into a framework where the first inner box is essentially cloned (duplicated) into the second box. Because of this "expansion", the visualization algorithm does not distinguish between the proof in \autoref{fig:vizexproof} and the redundant proof in \autoref{fig:vizexproof2}; both proofs when visualized would give the result shown in \autoref{fig:vizex}.

The algorithm could be made instead to draw an attack from $\{\beta\}$ on the left branch to $\{\gamma\}$ on the right. This would remove the redundancy and produce different visualizations for the different proofs in \autoref{fig:vizexproof} and \autoref{fig:vizexproof2}. The resulting visualizations however would not necessarily be trees. An interesting topic is the detection of similar subtrees in argument attack/defense chains and their pruning, resulting in less redundant and more concise proofs when the arguments are converted back into proofs. In addition, attacks and defenses could be moved to shallower levels in the tree if possible, in order for their corresponding boxes in the proof to appear in a shallower box-nesting level, so that their conclusions can be used in a wider context. Of course, this pruning and relocating of nodes in the tree must be done carefully, so that the resulting proofs always follow the Genuine Absurdity Property. This topic remains part of future work and is not discussed further in the report.

\begin{figure}[thp]
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\beta\wedge\alpha)&\mbox{given}\cr
2&\neg(\neg\beta\wedge\gamma)&\mbox{given}\cr
3&\neg(\alpha\wedge\neg\beta\wedge\neg\gamma)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\beta&\mbox{hypothesis}&\cr
&6&\beta\wedge\alpha&\wedge I(5,4)&\cr
&7&\bot&\bot I(1,6)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&8&\neg\beta&\neg I(5,7)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&9&\gamma&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&10&\beta&\mbox{hypothesis}&\cr
&11&\beta\wedge\alpha&\wedge I(10,4)&\cr
&12&\bot&\bot I(1,11)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&13&\neg\beta&\neg I(10,12)&\cr
%
&14&\neg\beta\wedge\gamma&\wedge I(13,9)&\cr
&15&\bot&\bot I(2,14)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&16&\neg\gamma&\neg I(9,15)&\cr
&17&\alpha\wedge\neg\beta&\wedge I(4,8)&\cr
&18&\alpha\wedge\neg\beta\wedge\neg\gamma&\wedge I(17,16)&\cr
&19&\bot&\bot I(3,18)&\cr
%
\noalign{\hrule}}}\,\cr
%
20&\neg\alpha&\neg I(4,19)\cr
}}\]
\caption{Example another proof that results in a framework like in \autoref{fig:vizex}. This proof is redundant but correct under the rules of natural deduction nevertheless.\label{fig:vizexproof2}}
\end{figure}

\section{Details of Implementation}
The algorithm first starts by reversing the proof so that it is in ascending order (opposite of the output by the theorem prover in \autoref{chap:prover}). \autoref{lst:argviz1} shows that after reversing the proof, the algorithm calls the \lstinline$getDefence/7$ predicate, which is responsible for producing the defense node as well as handling its subtree (which on the top level is the entire tree).

The \lstinline$getDefence/7$ (line 7 of the code) predicate adds the hypothesis of the box in the argumentation framework under construction and then calls \lstinline$getAttack/6$ which returns the attack and its subtree.

The \lstinline$getAttack/6$ (line 10 of the code) looks at the bottom of the box and finds the contradiction that will indicate what the attacks are (lines 11 to 16). If the contradiction is due to a conjunction of formulas then the individual components are found (line 19). If there is only one component (there is no conjunction) it is retrieved by line 22. If the contradiction was reached just by using the hypothesis itself, then the attack has no special components which makes it an empty set attack (line 25). A node is then made from the components for the argumentation framework that is being built (line 27) and then all components that were attempted to defend against are gathered. For each of those components, their respective subtrees are gathered (line 31) and finally all the new nodes and attacks between them are put together and returned (lines 32, 33). The predicate \lstinline$m2/2$ on lines 18, 21, 24 and 29 acts as an alias to the standard \lstinline$member/2$ Prolog predicate.

\begin{lstlisting}[caption={First part of the proof visualization algorithm},label=lst:argviz1]
% Converts a GAP proof to its argumentation representation
convertGAPToArg(Proof, [Nodes, AttDefs]) :-
	reverse(Proof, RevProof),
	getTheoryAndRevBox(RevProof, Theory, Box),
	getDefence(Box, Box, Theory, 1, 0, Nodes, [_|AttDefs]), !.
% Makes a node and defence relation against given attack (and handles its subtree as well)
getDefence([step(Hypothesis, [hypothesis], _)|Proof], WholeProof, Theory, You, Target, [[[Hypothesis], You]|Nodes], [[You, Target]|AttDefs]) :-
	getAttack(Proof, WholeProof, [Hypothesis|Theory], You, Nodes, AttDefs).
% Makes a node and attack relation against given defence (and handles its subtree as well)
getAttack(Proof, WholeProof, Ignore, N, Nodes, AttDefs) :-
	reverse(Proof, RevProof),
	(
		RevProof = [step(falsity, [falsityI, _, LN], _)|_];
		
		RevProof = [step(falsity, [check, _], _), step(falsity, [falsityI, _, LN], _)|_]
	),
	(
		m2(step(_, [andI|_], LN), Proof),
		findAttackComponents(Proof, WholeProof, Ignore, LN, Components), !;
		
		m2(step(X, _, LN), Proof),
		getAttackComponent(X, LN, Ignore, Proof, WholeProof, Components), !;
		
		not(m2(step(_, _, LN), Proof)),
		Components = []
	),
	makeAttackNode(Components, Attack),
	Ignore = [_|Theory],
	findall([AttComponent, DefAgainstAtt], m2([AttComponent, DefAgainstAtt], Components), DefendedAgainstComponents),
	ln(N, NextN), ln(NextN, NextNextN),
	getDefences(WholeProof, Theory, NextNextN, NextN, DefendedAgainstComponents, DNodes, DAttDefs),
	Nodes = [[Attack, NextN]|DNodes],
	AttDefs = [[NextN, N]|DAttDefs].
\end{lstlisting}

The predicate \lstinline$getDefences/7$ as shown in \autoref{lst:argviz2} is responsible for gathering all defenses and their subtrees. For each defense, it calls \lstinline$getDefence/7$ and it ensures that the nodes returned have different labels from the other defenses. The nodes and attack relations are then merged and returned. The predicate \lstinline$a2/3$ on lines 7 and 8 acts as an alias to the standard \lstinline$append/3$ Prolog predicate.

\begin{lstlisting}[caption={Second part of the proof visualization algorithm},label=lst:argviz2]
% Gathers all defences against an attack (and their subtrees)
getDefences(WholeProof, Theory, You, Target, [[_, Box]|Components], Nodes, AttDefs) :-
	getDefence(Box, WholeProof, Theory, You, Target, DNodes, DAttDefs),
	reverse(DNodes, [[_, LastId]|_]),
	ln(LastId, NewYou),
	getDefences(WholeProof, Theory, NewYou, Target, Components, DsNodes, DsAttDefs),
	a2(DNodes, DsNodes, Nodes),
	a2(DAttDefs, DsAttDefs, AttDefs).
getDefences(_, _, _, _, [], [], []).
\end{lstlisting}

The predicates \lstinline$findAttackComponents/5$ and \lstinline$getAttackComponent/6$ as shown in \autoref{lst:argviz3} work closely together in order to breakdown the conjunction of attack components. Conjunctions are gradually broken down into individual smaller parts (lines 9-15), until all that remains is atoms, negated atoms and negated formulas. If the attack component is part of the theory or the current hypothesis, it is ignored (line 17). If, on the other hand, it is a previous hypothesis (in other words a previous defense used earlier), then it is added as a terminal attack (an attack that cannot be defended against) (line 18). Alternatively, the attack component forms an attack that was attempted to defend against, and is returned along with the box containing the defense attempt (line 19). The individual components are then placed in one list and are returned (line 13). The predicate \lstinline$m2/2$ on lines 10 and 17 acts as an alias to the standard \lstinline$member/2$ Prolog predicate. The predicate \lstinline$a2/3$ on line 13 acts as an alias to the standard \lstinline$append/3$ Prolog predicate.

\begin{lstlisting}[caption={Third part of the proof visualization algorithm},label=lst:argviz3]
% Breaks down an attack into individual components and the defence attempts against them
% returns a list of a mixture of:
% [A] (for part of the attack used as defences up the tree - there's no way to attack them)
% [A, defAgainstA] (for part of the attack that was attempted to defend against, plus the box of the proof that does so)
% example: given attack a&b&¬c&d returns [[a], [[b], [...]], [[¬c], [...]]],
% assuming a was used as a defence above (you cannot defend against your defence, so this is a terminal part of the attack),
% there was an attempt to defend against b and ¬c (given by the parts of the proof [...]),
% and d was part of the theory hence there's no defence against that
findAttackComponents(Proof, WholeProof, Ignore, LN, Components) :-
	m2(step(and(A, B), [andI, LN1, LN2], LN), Proof),
	getAttackComponent(A, LN1, Ignore, Proof, WholeProof, Components1),
	getAttackComponent(B, LN2, Ignore, Proof, WholeProof, Components2),
	a2(Components1, Components2, Components).
getAttackComponent(and(_, _), LN, Ignore, Proof, WholeProof, Components) :-
	!, findAttackComponents(Proof, WholeProof, Ignore, LN, Components).
getAttackComponent(A, LN, Ignore, _, WholeProof, Component) :-
	m2(A, Ignore), Component = [], !;
	getStep(LN, WholeProof, step(A, [hypothesis], LN)), Component = [[A]], !;
	getBox(LN, WholeProof, _, Box), Component = [[A, Box]].
\end{lstlisting}

\section{Example Walkthough}
The example will revolve around the example proof given in \autoref{sec:vizalg}. The algorithm changes the format of the proof so that steps are in increasing order, in the same way as the proof would be printed on paper. The outer box is selected and \lstinline$getDefence/7$ is called upon to return the entire tree (lines 3-5 of \autoref{lst:argviz3}).

The predicate \lstinline$getDefence/7$ automatically creates and adds a node for the defense $\alpha$, the hypothesis of the outer box. It then assigns the duty of creating the rest of the tree to \lstinline$getAttack/6$ (line 8). Note that it adds the hypothesis to the ignore list.

This predicate looks at the bottom of the proof (line 15 of the proof, line 13 of the code) and then picks up the conjunction of components $\alpha\wedge\neg\beta\wedge\neg\gamma$ (line 14 of the proof, line 18 of the code). The predicate \lstinline$findAttackComponents/5$ is called to find and return the attack components.

\lstinline$findAttackComponents/5$ splits the conjunction in two parts, namely $\alpha$ and $\neg\beta\wedge\neg\gamma$ (line 10 of \autoref{lst:argviz3}). \lstinline$getAttackComponent/6$ is called on both parts.

For the first call, \lstinline$getAttackComponent/6$ realizes that the component $\alpha$ is an atom, and that it is included in the ignore list. Thus it returns empty-handed (line 17 of the code).

For the second call, \lstinline$getAttackComponent/6$ realizes that the component is actually another conjunction and calls \lstinline$findAttackComponents/5$ to split the conjunction into individual parts (line 15). The two parts are $\neg\beta$ and $\neg\gamma$. \lstinline$getAttackComponent/6$ is called on both parts.

\lstinline$getAttackComponent/6$ realizes that $\neg\beta$ is a negated atom and is not e member of the ignore list nor it is a previous defense. This means that an attempt to defend against it must have been done. Thus the component itself, along with its accompanying attempted defense box (lines 5-7 in the proof, line 19 in the code) are returned.

Similarly for the case of $\neg\gamma$, the component itself along with its box (lines 9-11 in the proof) are returned. The components find their way back to the first call of \lstinline$findAttackComponents/5$ which returns them in a single list back to \lstinline$getAttack/6$ (line 19 in \autoref{lst:argviz1}).

Continuing on line 27, the attack node $\{\neg\beta, \neg\gamma\}$ is made, and from the components of the attack, all that were attempted to be defended against are gathered (line 29). In this case there were attempts at defending against both $\neg\beta$ and $\neg\gamma$. \lstinline$getDefences/7$ is called to return the subtrees of the two attack components.

\lstinline$getDefences/7$ is a recursive predicate that finds the defenses (and the rest of the subtree) for each attack component. It also handles the labels for the subtrees so that they don't use the same identifiers. Note that the hypothesis $\alpha$ has been dropped from the ignore list.

\lstinline$getDefence/7$ is called in order to find the defense against $\neg\beta$. This is where the algorithm repeats all the steps of the walkthrough so far again, though this time the hypothesis is $\beta$. The major difference is that \lstinline$getAttackComponent/6$ will ignore the $\beta$ attack component (line 6 of the proof) but it will accept $\alpha$ as an attack that was previously used as a defense, making it a terminal component (ie there is no defending against that).

Similarly for $\neg\gamma$, the procedure is repeated and the results bubble back up to \lstinline$getDefences/7$, where those results are merged with the results of the defense attempt against $\neg\beta$ (lines 7-8 of \autoref{lst:argviz2}). The results that this predicate returns are merged with the attack node $\{\neg\beta, \neg\gamma\}$ from line 27 of \autoref{lst:argviz1} in order to produce the entire subtree of the attack $\{\neg\beta, \neg\gamma\}$ against $\alpha$ (lines 32-33). The results are then pushed upwards and the end result is the tree shown in \autoref{fig:vizex}.

\section{Visualization Examples}
\label{sec:vizex}
This section illustrates the function of the algorithm with more examples. For each example, the proof is given alongside its visual representation according to the visualization algorithm.

\begin{figure}[thp]
\begin{minipage}[c]{.5\linewidth}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\beta\wedge\alpha)&\mbox{given}\cr
2&\neg(\alpha\wedge\gamma)&\mbox{given}\cr
3&\neg(\alpha\wedge\neg\beta\wedge\neg\gamma)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\beta&\mbox{hypothesis}&\cr
&6&\beta\wedge\alpha&\wedge I(5,4)&\cr
&7&\bot&\bot I(1,6)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&8&\neg\beta&\neg I(5,7)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&9&\gamma&\mbox{hypothesis}&\cr
&10&\alpha\wedge\gamma&\wedge I(4,9)&\cr
&11&\bot&\bot I(2,10)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&12&\neg\gamma&\neg I(9,11)&\cr
&13&\alpha\wedge\neg\beta&\wedge I(4,8)&\cr
&14&\alpha\wedge\neg\beta\wedge\neg\gamma&\wedge I(13,12)&\cr
&15&\bot&\bot I(3,14)&\cr
%
\noalign{\hrule}}}\,\cr
%
16&\neg\alpha&\neg I(4,15)\cr
}}\]
\end{minipage}%
\begin{minipage}[c]{.5\linewidth}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\alpha\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\beta, \neg\gamma\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\beta\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
		]
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\gamma\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
		]
	]
]
\end{forest}}
\end{minipage}%
\caption{Visualization example of 2-level boxes}
\end{figure}

\begin{figure}[thp]
\begin{minipage}[c]{.5\linewidth}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\alpha\wedge\beta)&\mbox{given}\cr
2&\neg\neg\beta&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&3&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\neg\beta&\mbox{hypothesis}&\cr
&5&\bot&\bot I(2,4)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&6&\neg\neg\beta&\neg I(4,5)&\cr
&7&\beta&\neg E(6)&\cr
&8&\alpha\wedge\beta&\wedge I(3,7)&\cr
&9&\bot&\bot I(1,8)&\cr
%
\noalign{\hrule}}}\,\cr
%
10&\neg\alpha&\neg I(3,9)\cr
}}\]
\end{minipage}%
\begin{minipage}[c]{.5\linewidth}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\alpha\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\beta\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\neg\beta\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\}$}}]
		]
	]
]
\end{forest}}
\end{minipage}%
\caption{Visualization example of empty set attack\label{fig:emptysetattack}}
\end{figure}

\begin{figure}[thp]
\begin{minipage}[c]{.5\linewidth}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\alpha\wedge\beta)&\mbox{given}\cr
2&\neg(\alpha\wedge\gamma)&\mbox{given}\cr
3&\neg(\alpha\wedge\delta)&\mbox{given}\cr
4&\neg(\alpha\wedge\neg\beta\wedge\neg\gamma)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&6&\beta&\mbox{hypothesis}&\cr
&7&\alpha\wedge\beta&\wedge I(5,6)&\cr
&8&\bot&\bot I(1,7)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&9&\neg\beta&\neg I(6,8)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&10&\delta&\mbox{hypothesis}&\cr
&11&\alpha\wedge\delta&\wedge I(5,10)&\cr
&12&\bot&\bot I(3,11)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&13&\neg\delta&\neg I(10,12)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&14&\gamma&\mbox{hypothesis}&\cr
&15&\alpha\wedge\gamma&\wedge I(5,14)&\cr
&16&\bot&\bot I(2,15)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&17&\neg\gamma&\neg I(14,16)&\cr
&18&\alpha\wedge\neg\beta&\wedge I(5,9)&\cr
&19&\alpha\wedge\neg\beta\wedge\neg\gamma&\wedge I(18,17)&\cr
&20&\bot&\bot I(4,19)&\cr
%
\noalign{\hrule}}}\,\cr
%
21&\neg\alpha&\neg I(5,20)\cr
}}\]
\end{minipage}%
\begin{minipage}[c]{.5\linewidth}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\alpha\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\beta, \neg\gamma\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\beta\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
		]
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\gamma\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
		]
	]
]
\end{forest}}
\end{minipage}%
\caption{Visualization example of ignored successful defense}
\end{figure}

\begin{figure}[thp]
\begin{minipage}[c]{.5\linewidth}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\neg\alpha\wedge\delta)&\mbox{given}\cr
2&\neg(\alpha\wedge\neg\beta)&\mbox{given}\cr
3&\neg(\alpha\wedge\gamma)&\mbox{given}\cr
4&\neg(\alpha\wedge\beta\wedge\neg\gamma)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\delta&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&6&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&7&\neg\beta&\mbox{hypothesis}&\cr
&8&\alpha\wedge\neg\beta&\wedge I(6,7)&\cr
&9&\bot&\bot I(2,8)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&10&\beta&\neg I(7,9)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&11&\gamma&\mbox{hypothesis}&\cr
&12&\alpha\wedge\gamma&\wedge I(6,11)&\cr
&13&\bot&\bot I(3,12)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&14&\neg\gamma&\neg I(11,13)&\cr
&15&\alpha\wedge\beta&\wedge I(6,10)&\cr
&16&\alpha\wedge\beta\wedge\neg\gamma&\wedge I(15,14)&\cr
&17&\bot&\bot I(4,17)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&18&\neg\alpha&\neg I(6,17)&\cr
&19&\neg\alpha\wedge\delta&\wedge I(18,5)&\cr
&20&\bot&\neg I(1,19)&\cr
%
\noalign{\hrule}}}\,\cr
%
21&\neg\delta&\neg I(5,20)\cr
}}\]
\end{minipage}%
\begin{minipage}[c]{.5\linewidth}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\delta\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\alpha\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\alpha\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\beta, \neg\gamma\}$}}
				[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\neg\beta\}$}}
					[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
				]
				[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\gamma\}$}}
					[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
				]
			]
		]
	]
]
\end{forest}}
\end{minipage}%
\caption{Visualization example of 3-level boxes}
\end{figure}

\begin{figure}[thp]
\begin{minipage}[c]{.5\linewidth}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\gamma&\mbox{given}\cr
2&\neg(\alpha\wedge\beta\wedge\gamma)&\mbox{given}\cr
3&\neg(\alpha\wedge\neg\beta)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&4&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&5&\neg\beta&\mbox{hypothesis}&\cr
&6&\alpha\wedge\neg\beta&\wedge I(4,5)&\cr
&7&\bot&\bot I(3,6)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&8&\neg\neg\beta&\neg I(5,7)&\cr
&9&\beta&\neg E(8)&\cr
&10&\alpha\wedge\beta&\wedge I(4,9)&\cr
&11&\alpha\wedge\beta\wedge\gamma&\wedge I(10,1)&\cr
&12&\bot&\bot I(2,11)&\cr
%
\noalign{\hrule}}}\,\cr
%
13&\neg\alpha&\neg I(4,12)\cr
}}\]
\end{minipage}%
\begin{minipage}[c]{.5\linewidth}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\alpha\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\beta\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\neg\beta\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
		]
	]
]
\end{forest}}
\end{minipage}%
\caption{Visualization example of theory attack}
\end{figure}

\begin{figure}[thp]
\begin{minipage}[c]{.5\linewidth}
\[\vbox{\offinterlineskip\halign{
&\tabskip=1.5em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\tabskip=0em\cr
%
1&\neg(\neg\alpha\wedge\delta\wedge\epsilon)&\mbox{given}\cr
2&\neg(\alpha\wedge\neg\beta)&\mbox{given}\cr
3&\neg(\alpha\wedge\gamma)&\mbox{given}\cr
4&\neg(\alpha\wedge\beta\wedge\neg\gamma)&\mbox{given}\cr
5&\neg(\neg\delta\wedge\epsilon)&\mbox{given}\cr
6&\neg(\zeta\wedge\eta)&\mbox{given}\cr
7&\neg(\zeta\wedge\neg\eta\wedge\neg\epsilon)&\mbox{given}\cr
%
\multispan3\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&8&\zeta&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&9&\epsilon&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&10&\alpha&\mbox{hypothesis}&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&11&\neg\beta&\mbox{hypothesis}&\cr
&12&\alpha\wedge\neg\beta&\wedge I(10,11)&\cr
&13&\bot&\bot I(2,12)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&14&\beta&\neg I(11,13)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&15&\gamma&\mbox{hypothesis}&\cr
&16&\alpha\wedge\gamma&\wedge I(10,15)&\cr
&17&\bot&\bot I(3,16)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&18&\neg\gamma&\neg I(15,17)&\cr
&19&\alpha\wedge\beta&\wedge I(10,14)&\cr
&20&\alpha\wedge\beta\wedge\neg\gamma&\wedge I(19,18)&\cr
&21&\bot&\bot I(4,20)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&22&\neg\alpha&\neg I(10,21)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&23&\neg\delta&\mbox{hypothesis}&\cr
&24&\neg\delta\wedge\epsilon&\wedge I(23,9)&\cr
&25&\bot&\bot I(5,24)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&26&\delta&\neg I(23,25)&\cr
&27&\neg\alpha\wedge\delta&\wedge I(22,26)&\cr
&28&\neg\alpha\wedge\delta\wedge\epsilon&\wedge I(27,9)&\cr
&29&\bot&\bot I(1,28)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&30&\neg\epsilon&\neg I(9,29)&\cr
%
&\multispan3\,\vbox{\halign{
\vrule#&&\hskip.1em\tabskip=1em#\strut&$#$\hfil\tabskip=1em&\hfil$#$\hskip0.1em\tabskip=0em&\vrule#\cr
\noalign{\hrule}
%
&31&\eta&\mbox{hypothesis}&\cr
&32&\zeta\wedge\eta&\wedge I(8,31)&\cr
&33&\bot&\bot I(6,32)&\cr
%
\noalign{\hrule}}}\,&\cr
%
&34&\neg\eta&\neg I(31,33)&\cr
&35&\zeta\wedge\neg\eta&\wedge I(8,34)&\cr
&36&\zeta\wedge\neg\eta\wedge\neg\epsilon&\wedge I(35,30)&\cr
&37&\bot&\bot I(7,36)&\cr
%
\noalign{\hrule}}}\,\cr
%
38&\neg\zeta&\neg I(8,37)\cr
}}\]
\end{minipage}%
\begin{minipage}[c]{.5\linewidth}
\centerline{\begin{forest}
forestyle
[,tikz={\node[pos=0,font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{$\{\zeta\}$};}
	[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\epsilon, \neg\eta\}$}}
		[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\epsilon\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\alpha, \delta\}$}}
				[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\alpha\}$}}
					[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\beta, \neg\gamma\}$}}
						[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\neg\beta\}$}}
							[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
						]
						[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\gamma\}$}}
							[,edge label={node[font=\sffamily,anchor=west,xshift=12pt,yshift=1pt]{\color{black}$\{\alpha\}$}}]
						]
					]
				]
				[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\neg\delta\}$}}
					[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\epsilon\}$}}]
				]
			]
		]
		[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\eta\}$}}
			[,edge label={node[font=\sffamily,anchor=west,xshift=8pt,yshift=1pt]{\color{black}$\{\zeta\}$}}]
		]
	]
]
\end{forest}}
\end{minipage}%
\caption{Visualization example of 4-level boxes}
\end{figure}

\chapter{Server Module}
\label{chap:server}
TODO

\chapter{Client Module}
\label{chap:client}
TODO

\chapter{Evaluation}
\label{chap:eval}
TODO

\chapter{Conclusion}
\label{chap:chiliconclusion}

\listoffigures

\lstlistoflistings

\bibliographystyle{plainnat}
\bibliography{justin}

\end{document}